---
output:
  pdf_document: default
  html_document: default
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
library(printr)
library(ggplot2)
library(cowplot)
library(reshape2)
library(knitr)
library(gmodels)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df_meta <- read.csv("~/master/wolf/dataflow/00-meta/wetzels2018_wu2018_fastq.csv")
colnames(df_meta)[1] <- "sra_accession"

df_meta$sra_accession <- as.character(df_meta$sra_accession)
df_meta$type <- as.character(df_meta$type)
df_meta$study <- as.character(df_meta$study)
df_meta$region <- as.character(df_meta$region)
df_meta$sample <- as.character(df_meta$sample)
df_meta$pack <- as.character(df_meta$pack)
df_meta$sibling <- as.character(df_meta$sibling)
df_meta$replicate <- as.character(df_meta$replicate)
df_meta$sample_id <- as.character(df_meta$sample_id)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df_classification  <- read.csv("~/master/wolf/dataflow/03-asv-taxonomy/wetzels2018-8_270_8_220-100-rdp.csv")
df_classification[,1] <- NULL
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df <- read.delim("~/master/wolf/dataflow/03-asv-table/wetzels2018-8_270_8_220-100.txt", skip = 1, header = TRUE)
df$clustering <- 100
colnames(df)[1] <- 'asv_id'

col_to_gather <- names(df)[!(startsWith(names(df), "W"))]
df <- melt(df, id = col_to_gather)
colnames(df)[3:4] <- c('sra_accession', 'count')

df$asv_id <- as.character(df$asv_id)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df_normalization <- df %>%
  filter(clustering == 100) %>%
  group_by(sra_accession) %>%
  mutate(total_reads = sum(count)) %>%
  ungroup() %>%
  select(sra_accession, total_reads) %>%
  ungroup() %>%
  distinct() 

df_classification <- df_classification %>%
  select(asv_id, phylum, family, genus)


df_complete <- inner_join(df, df_meta) %>%
  inner_join(df_normalization) %>%
  inner_join(df_classification)

df_normalization_plot <- inner_join(df_normalization, df_meta)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
df_metrics <- df_complete %>% 

  mutate(count_norm = (count / total_reads)*100) %>%
  
  group_by(sample_id, asv_id) %>%
  
  mutate(count_norm = median(count_norm)) %>%
  
  ungroup() %>%
  
  unite(classification, c("phylum", "family", "genus"), sep = ";", remove = FALSE) %>%
  
  select(-sra_accession, -replicate) %>%
  
  distinct() %>%
  
  rowwise() %>%
  
  mutate(above_0 = ifelse(count_norm != 0, 1, 0)) %>%
  
  group_by(pack, sample) %>%
  
  mutate(npack = length(unique(sample_id))) %>%
  
  ungroup() %>%
  
  filter(npack > 2) %>%
  
  group_by(asv_id, sample) %>%
  
  mutate(nsamples = sum(above_0)) %>% 
           
  ungroup() %>%
  
  filter(nsamples > 2) %>%
  
  group_by(asv_id, pack) %>%
  
  mutate(contains_0 = ifelse(0 %in% above_0, 0, 1)) %>%
  
  ungroup() %>%
  
  group_by(asv_id) %>%
  
  mutate(all_contains_0 = ifelse(sum(contains_0) == 0, TRUE, FALSE)) %>%
  
  ungroup() %>%
  
  filter(all_contains_0 == FALSE)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
df_phlycounts_counts <- df_metrics %>%
  select(asv_id, sample_id, count) %>%
  spread(sample_id, count)

df_phlycounts_counts[is.na(df_phlycounts_counts)] <- 0

df_phlycounts_counts <- df_phlycounts_counts[order(df_phlycounts_counts$asv_id),] 

numsamples <- length(df_phlycounts_counts)

otumat <- as.matrix(df_phlycounts_counts[,2:numsamples])
rownames(otumat) <- as.data.frame(df_phlycounts_counts)[,1]

df_phlycounts_tax <- df_metrics %>%
  select(asv_id, phylum, family, genus) %>%
  unique()

df_phlycounts_tax$phylum <- as.character(df_phlycounts_tax$phylum)
df_phlycounts_tax$family <- as.character(df_phlycounts_tax$family)
df_phlycounts_tax$genus <- as.character(df_phlycounts_tax$genus)

df_phlycounts_tax[is.na(df_phlycounts_tax)] <- "NotAssigned"

df_phlycounts_tax <- df_phlycounts_tax[order(df_phlycounts_tax$asv_id),] 

taxmat <- as.matrix(df_phlycounts_tax[,2:4])
rownames(taxmat) <- as.data.frame(df_phlycounts_tax)[,1]

df_phylocounts_meta <- df_metrics %>% 
  select(sample_id, sample, pack, sibling, cam) %>%
  unique() %>%
  rowwise() %>%
  ungroup()

df_phylocounts_meta$sample <- as.factor(df_phylocounts_meta$sample)
df_phylocounts_meta$pack <- as.factor(df_phylocounts_meta$pack)
df_phylocounts_meta$sibling <- as.factor(df_phylocounts_meta$sibling)
df_phylocounts_meta$cam <- as.factor(df_phylocounts_meta$cam)

df_phylocounts_meta <- as.data.frame(df_phylocounts_meta)

row.names(df_phylocounts_meta) <- df_phylocounts_meta[,1]
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=20, fig.height=25}
library("phyloseq")
library("ape")
library("DESeq2")

OTU = otu_table(otumat, taxa_are_rows = TRUE)
TAX = tax_table(taxmat)
physeq = phyloseq(OTU, TAX)

#fast_tree = read.tree("~/master/wolf/dataflow/02-trees/wetzels2018-8_270_8_220-97.out")
#random_tree = rtree(ntaxa(physeq), rooted=TRUE, tip.label=taxa_names(physeq))

samplesdata <- sample_data(df_phylocounts_meta)

physeq = phyloseq(OTU, TAX, samplesdata)

physeq = subset_samples(physeq, sample == "fecal")


diagdds = phyloseq_to_deseq2(physeq, ~ pack)

# calculate geometric means prior to estimate size factors
#gm_mean = function(x, na.rm=TRUE){
#  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
#}

#geoMeans = apply(counts(diagdds), 1, gm_mean)
#diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)

diagdds = DESeq(diagdds, fitType = "parametric", test = "Wald")

res = results(diagdds, cooksCutoff = FALSE)
alpha = 0.001
sigtab = res[which(res$padj < alpha), ]
sigtab = cbind(as(sigtab, "data.frame"), as(tax_table(physeq)[rownames(sigtab), ], "matrix"))

selected_seq_ids <- row.names(sigtab)

df_plot <- df_metrics[df_metrics$asv_id %in% selected_seq_ids,]

df_plot <- df_plot %>%
  filter(sample == "fecal")

ggplot(df_plot, aes(x=pack, y=count)) + 
            geom_point(aes(colour = pack), size = 3) + 
  facet_wrap( ~ asv_id, scales="free")
```

\newpage

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=20, fig.height=25}
ggplot(df_plot, aes(x=pack, y=count_norm)) + 
            geom_point(aes(colour = pack), size = 3) + 
  facet_wrap( ~ genus, scales="free")
```